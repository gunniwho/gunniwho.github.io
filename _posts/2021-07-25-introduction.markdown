---
layout: post
title:  "Introduction"
date:   2021-07-25 12:15:14 +0000
tags: [general, tech]
---
This is the first post on my new blog. I've been thinking about starting a blog for a while now but never actually made the time to do it. But now I'm stuck in a hotel room, quarantined from my family due to the COVID-19 pandemic, with nothing else but time (and my laptop) on my hands. Let's make it count!

I am an engineer. I studied electrical and computer engineering at the University of Iceland and then did my master's at Boston University, where I studied statistical signal processing. After graduating though, I went straight into software engineering. I started my career in the "web team" at a local insurance company but soon a job ad that practically had my name on it found its way to me. It was for a junior engineer position at a local startup building a cloud based medical system and they needed someone who understood both the client-server stuff and the signal processing stuff. I was there for close to 7 years and in my time there I contributed extensively to the first two versions of that system but I also _learned a lot_. 

When I left the system was processing about 1500 hours worth of recorded bio-signals and accompanying video every month. The usage had been steadily increasing for a while and was projected to grow quite rapidly for the forseeable future. I was really proud of what we had built and accomplished but it also felt like we were not really equipped to efficiently deal with the projected growth. As an example, we were manually deploying our services to VMs, one per customer. This had worked out ok for us in the past with a little more than a handful of customers but it was obviously not sustainable. 

The design had some really good things going for it that enabled us to iterate relatively quickly with a (really) small team of engineers working on it. But as time passed and things like containers, continuous delivery and devops became things I couldn't shake the feeling that we were not setting ourselves up for future success. We were stuck running services on windows servers, had stateful workloads that were impossible to scale out and were relying heavily on having a fast file system containing all that recorded data. All of those design decisions were purely a consequence of the time at which that system was originally conceived and were probably the best decisions that could be made given the circumstances. Fixing any of this would require a great big rewrite of something that wasn't even broken at the time so I really felt stuck. I couldn't stop thinking about how we might do things differently in the era of _cloud native systems_ and how people were doing this in the big(ger) leagues (our company only counted about 20 people at the time). Another job opportunity presented itself at a local fintech counting about 60 people at the time and I jumped.

My new role was senior software engineer in the core services team. I was super excited about being able to work solely on the backend of a system that already had a global presence. Surprisingly, that system was suffering from almost the exact same issues I had forseen at my previous job, only this one was seeing more usage and the strain was starting to show. Arguably, the system was definitely more mature than the one I had previously worked on. It had already been converted into a set of REST APIs and static front-ends so it was capable of scaling in theory. In practice it was so tightly coupled with the underlying relational database that the DB server would always be the bottleneck for the entire system. What they had done was essentially creating a distributed monolith. The DB scaling problem had been "dealt with" by sharding the DB at the application level, requiring the application developers to make sure they were working on the correct shard _for every single action that was being done_. This was incredibly cumbersome, not to mention error prone. It was still probably the right decision at the time (the alternative would probably have been a redesign) but the execution was less than optimal.

Despite the problems, again _I learned a lot_. After all, by changing jobs at that time I probably jumped ahead by a couple of years or more in terms of what problems I was dealing with. I still kept thinking how might we do what we do using techniques from the cloud native era such that the scaling and reliability problems are neatly taken care of while maintaining a nice developer experience for application developers. I would really like for the application developer experience to be simple. At the same time I'm really not a fan of building your own frameworks for that purpose. I think the smartest way is to find a piece of infrastructure that provides the functionality required. Application developers should not have to come up with _job frameworks_ or _cluster managers_ or anything of that sort to provide the features requested of them. The application should be agnostic of scheduling jobs or picking leaders or selecting database shards. It should just do what is specified in the requirements. Whatever else is needed for it to be able to _reliably_ fulfil those requirements should be provided by infrastructure external to the application. Ideally, the application shouldn't event have to be aware of those things. In the cases where that's unavoidable, the functionality should be provided with APIs from external infrastructure. 

At the time I was very excited about [Azure Service Fabric](https://azure.microsoft.com/en-us/services/service-fabric/) as an application development platform. It had everything from workload scheduling to reliable state management to virtual actors to observability. As it turned out though, I never got to work on a service fabric application. Another job opportunity presented itself and this time it was for a greenfield kubernetes application. I was already frustrated with my situation at the fintech, although in retrospect it shouldn't have come as a surprise that the situation was similar to what it had been at the medtech - after all they were founded within a year of each other. So how could I not jump?

The new position was a senior software engineer role at another medtech that was already established as a capital equipment provider but wanted to make a services offering in the cloud. The only concrete decision was that they were going to build on top of kubernetes. It sounds pretty crazy to have made that decision up front without even having layed down a single functional requirement for what was supposed to be built. Yet this was probably the best thing that could have happened to my career.

While kubernetes is nowhere near being an _application development platform_ like service fabric is, it's still a fantastic piece of infrastructure that already solves many of the problems of old on its own. What it lacks in built-in functionality, it makes up with a fantastic extensibility and an ecosystem of extensions. Being a team of only two engineers, we decided from the start that we would rely heavily on managed infrastructure - we were not going to waste our precious time on running or - god forbid - building infrastructure. In the cases where there are no managed offerings, we will always bet on an open source project rather than building anything ourselves. Our current stack includes Kafka for partitioned logs, S3, MonogoDB and Postgres for state and [Argo](https://argoproj.github.io/argo-workflows/) for workflows. To supercharge our application development experience we use [Dapr](https://dapr.io). Finally, to supercharge our application deployment experience we use [Pulumi](https://pulumi.com). All in all I think we're in a really good place with our tech stack and I'm actually amazed at how much we've accomplished with our limited resources so far.